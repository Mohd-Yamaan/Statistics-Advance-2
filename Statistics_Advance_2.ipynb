{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1: What is hypothesis testing in statistics?\n",
        "\n",
        "**Answer -** Hypothesis testing is a way in statistics to make decisions based on sample data. We usually start with an assumption, called a hypothesis, and then collect data to test if it is true or not. This process helps us to guess about a population based on small sample. It's like checking if what we belive is actually true or just by chance.\n",
        "\n",
        "Q2: What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "\n",
        "**Answer -** The null hypothesis (Ho) is like the starting point. It says there is no effect or no change. On the other hand, the alternative hypothesis (H1 or Ho) is what we think might be true instead. So, null is like “nothing is happening” and alternative is “something is happening”. We test the data to decide if we can reject the null.\n",
        "\n",
        "Q3: What is the significance level in hypothesis testing, and why is it important?\n",
        "\n",
        "**Answer -** Significance level (usually denoted by alpha, like 0.05) tells us how much risk we are willing to take to reject the null hypothesis when it is actually true. It's a threshold value. If our p-value is less than alpha, we reject the null. It's important because it controls the chance of making mistake in decision.\n",
        "\n",
        "Q4: What does a P-value represent in hypothesis testing?\n",
        "\n",
        "**Answer -** P-value is the probability of getting a result as extreme as our data, assuming the null hypothesis is true. It shows how likely our sample result is if the null is right. Smaller p-value means more strong evidence against the null.\n",
        "\n",
        "Q5: How do you interpret the P-value in hypothesis testing?\n",
        "\n",
        "**Answer -** If the p-value is smaller than significance level (like 0.05), we reject the null hypothesis. It means the result is statistically significant. If p-value is big, we don't have enough proof to reject the null.\n",
        "\n",
        "Q6: What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "\n",
        "**Answer -** Type 1 error happens when we reject the null hypothesis even though it's actually true. Type 2 error is when we don't reject the null even though the alternative is true. So basically, Type 1 is false positive and Type 2 is false negative.\n",
        "\n",
        "Q7: What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "\n",
        "**Answer -** In one-tailed test, we check only in one direction (either greater or less). In two-tailed, we check both directions (greater or less than). Two-tailed is more strict because we divide the alpha into two sides of the distribution.\n",
        "\n",
        "Q8: What is the Z-test, and when is it used in hypothesis testing?\n",
        "\n",
        "**Answer -** Z-test is used when the population standard deviation is known and sample size is large (usually more than 30). It helps to test mean or proportion when data is normally distributed. It uses Z-score to check how far the sample mean is from population mean.\n",
        "\n",
        "Q9: How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "\n",
        "**Answer -** Z-score = (sample mean - population mean) / (standard deviation / √n). It shows how many standard deviations our sample is away from the population mean. If Z-score is too high or low, the sample is unlikely under the null hypothesis.\n",
        "\n",
        "Q10: What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "\n",
        "**Answer -** T-distribution is similar to normal but it has fatter tails. It is used when sample size is small (less than 30) or population standard deviation is unknown. It gives better results in those conditions.\n",
        "\n",
        "Q11: What is the difference between a Z-test and a T-test?\n",
        "\n",
        "**Answer -** Z-test is for large samples and known standard deviation. T-test is for small samples or unknown standard deviation. Also, T-test uses t-distribution while Z-test uses normal distribution.\n",
        "\n",
        "Q12: What is the T-test, and how is it used in hypothesis testing?\n",
        "\n",
        "**Answer -** T-test is a statistical test that helps to compare means. It is used to see if the average of two groups are different or not. We use it when sample is small and standard deviation is unknown. There are different types like one-sample, two-sample, and paired t-test.\n",
        "\n",
        "Q13: What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "\n",
        "**Answer -** Both are used for comparing means, but based on different conditions. When sample is big and standard deviation is known, we use Z-test. When sample is small or we don’t know standard deviation, we use T-test.\n",
        "\n",
        "Q14: What is a confidence interval, and how is it used to interpret statistical results?\n",
        "\n",
        "**Answer -** onfidence interval gives a range of values where we believe the true value lies. For example, 95% confidence interval means we are 95% sure the actual value is inside that range. It helps to understand the uncertainty in estimate.\n",
        "\n",
        "Q15: What is the margin of error, and how does it affect the confidence interval?\n",
        "\n",
        "**Answer -** Margin of error is how much we allow the estimate to vary. Bigger margin means wider confidence interval, smaller margin means more precise result. It depends on sample size and standard deviation.\n",
        "\n",
        "Q16: How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "**Answer -** Bayes' Theorem helps us to update our beliefs based on new data. It is very useful in probability and decision-making. It combines prior knowledge with new evidence to calculate updated probabilities.\n",
        "\n",
        "Q17: What is the Chi-square distribution, and when is it used?\n",
        "\n",
        "**Answer -** Chi-square distribution is used for testing relationships between categorical variables. It is right-skewed and only positive. Mostly used in tests like goodness of fit or independence test.\n",
        "\n",
        "Q18: What is the Chi-square goodness of fit test, and how is it applied?\n",
        "\n",
        "**Answer -** Goodness of fit test checks if the observed data match the expected distribution. For example, if we expect equal number of red, blue, green balls, we can use this test to see if real counts match that.\n",
        "\n",
        "Q19: What is the F-distribution, and when is it used in hypothesis testing?\n",
        "\n",
        "**Answer -** F-distribution is used for comparing variances between groups. It is used in ANOVA and regression models. It is also right-skewed like chi-square.\n",
        "\n",
        "Q20: What is an ANOVA test, and what are its assumptions?\n",
        "\n",
        "**Answer -** ANOVA (Analysis of Variance) checks if more than two group means are different. It assumes that samples are independent, normal distributed, and have equal variances. If ANOVA shows significance, it means at least one group is different.\n",
        "\n",
        "Q21: What are the different types of ANOVA tests?\n",
        "\n",
        "**Answer -** There are mainly three types: One-way ANOVA (for one factor), Two-way ANOVA (two factors), and Repeated Measures ANOVA (same subject tested multiple times). Each has different uses based on the design.\n",
        "\n",
        "Q22: What is the F-test, and how does it relate to hypothesis testing?\n",
        "\n",
        "**Answer -** F-test is used to compare two variances. It is the base for ANOVA test. If F value is big and p-value is low, we reject null and say there is a significant difference between group variances.\n",
        "\n"
      ],
      "metadata": {
        "id": "KkG4yONA_-LS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "interpret the results@"
      ],
      "metadata": {
        "id": "gb9JYMi9HXjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "# sample data\n",
        "sample = [12, 15, 14, 10, 13, 16, 14, 12, 13, 15]\n",
        "sample_mean = np.mean(sample)\n",
        "population_mean = 13\n",
        "population_std = 2  # known population standard deviation\n",
        "n = len(sample)\n",
        "\n",
        "# Z-test\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(n))\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "print(\"Z-score:\", z_score)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject null hypothesis. Sample mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis. No significant difference found.\")\n"
      ],
      "metadata": {
        "id": "ssneVKTkHfsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python@\n"
      ],
      "metadata": {
        "id": "fyEMpuz3JQsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# simulate 100 values from normal distribution\n",
        "data = np.random.normal(loc=50, scale=5, size=100)\n",
        "\n",
        "# population mean to test against\n",
        "pop_mean = 52\n",
        "\n",
        "# one-sample t-test\n",
        "t_stat, p_val = stats.ttest_1samp(data, pop_mean)\n",
        "\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_val)\n",
        "\n",
        "if p_val < 0.05:\n",
        "    print(\"Reject null, the sample mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null, no significant difference found.\")\n"
      ],
      "metadata": {
        "id": "V6gncefdHh5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Implement a one-sample Z-test using Python to compare the sample mean with the population mean@\n"
      ],
      "metadata": {
        "id": "Uyna89TSJVxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# given sample\n",
        "data = np.array([25, 27, 24, 26, 28, 29, 30])\n",
        "sample_mean = np.mean(data)\n",
        "pop_mean = 26\n",
        "pop_std = 2  # known\n",
        "\n",
        "n = len(data)\n",
        "z = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
        "p = 2 * (1 - norm.cdf(abs(z)))\n",
        "\n",
        "print(\"Z-Statistic:\", z)\n",
        "print(\"P-Value:\", p)\n",
        "\n",
        "if p < 0.05:\n",
        "    print(\"Sample is significantly different from population mean.\")\n",
        "else:\n",
        "    print(\"No significant difference from population mean.\")\n"
      ],
      "metadata": {
        "id": "MCVrSEosHh0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot@\n"
      ],
      "metadata": {
        "id": "HWis-NipJgRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# sample data\n",
        "sample = [55, 52, 53, 54, 56, 58, 52, 54, 57, 53]\n",
        "sample_mean = np.mean(sample)\n",
        "pop_mean = 54\n",
        "pop_std = 2\n",
        "n = len(sample)\n",
        "\n",
        "# Z-test\n",
        "z = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
        "p_value = 2 * (1 - norm.cdf(abs(z)))\n",
        "\n",
        "print(\"Z-score:\", z)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Visualize\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "plt.plot(x, y, label='Normal Distribution')\n",
        "plt.axvline(z, color='red', linestyle='--', label=f'Z-score = {z:.2f}')\n",
        "plt.axvline(-1.96, color='green', linestyle=':', label='Critical Z = ±1.96')\n",
        "plt.axvline(1.96, color='green', linestyle=':')\n",
        "\n",
        "plt.title('Two-tailed Z-test Decision Region')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uTfDVGyGHhv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Perform a two-tailed Z-test using Python and visualize the decision region on a plot@\n"
      ],
      "metadata": {
        "id": "hgn_gL9GJi4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_type_errors(mu0, mu1, sigma, alpha=0.05):\n",
        "    z_critical = norm.ppf(1 - alpha/2)\n",
        "    x = np.linspace(mu0 - 4*sigma, mu1 + 4*sigma, 1000)\n",
        "\n",
        "    y_null = norm.pdf(x, mu0, sigma)\n",
        "    y_alt = norm.pdf(x, mu1, sigma)\n",
        "\n",
        "    plt.plot(x, y_null, label='Null Hypothesis (H0)', color='blue')\n",
        "    plt.plot(x, y_alt, label='Alternative Hypothesis (H1)', color='orange')\n",
        "\n",
        "    critical_left = mu0 - z_critical * sigma\n",
        "    critical_right = mu0 + z_critical * sigma\n",
        "\n",
        "    plt.axvline(critical_left, color='red', linestyle='--', label='Critical Region')\n",
        "    plt.axvline(critical_right, color='red', linestyle='--')\n",
        "\n",
        "    plt.fill_between(x, 0, y_null, where=(x < critical_left) | (x > critical_right), color='blue', alpha=0.3, label='Type I Error')\n",
        "    plt.fill_between(x, 0, y_alt, where=(x >= critical_left) & (x <= critical_right), color='orange', alpha=0.3, label='Type II Error')\n",
        "\n",
        "    plt.title('Type I and Type II Errors')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_type_errors(mu0=50, mu1=52, sigma=3)\n"
      ],
      "metadata": {
        "id": "eR_ruHBvHhq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to perform an independent T-test and interpret the results@\n"
      ],
      "metadata": {
        "id": "LwSY3kcnJsJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "import numpy as np\n",
        "\n",
        "# two independent samples\n",
        "group1 = [22, 25, 27, 24, 28, 26, 23]\n",
        "group2 = [30, 32, 28, 29, 33, 31, 30]\n",
        "\n",
        "# perform t-test\n",
        "t_stat, p_value = ttest_ind(group1, group2)\n",
        "\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"There is significant difference between the two groups.\")\n",
        "else:\n",
        "    print(\"There is no significant difference between the groups.\")\n"
      ],
      "metadata": {
        "id": "VKVjsm4lHhmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Perform a paired sample T-test using Python and visualize the comparison results@\n"
      ],
      "metadata": {
        "id": "VPtkGXI3JxiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_rel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "before = [80, 85, 78, 90, 87]\n",
        "after = [83, 88, 79, 91, 89]\n",
        "\n",
        "# Paired t-test\n",
        "t_stat, p_val = ttest_rel(before, after)\n",
        "\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_val)\n",
        "\n",
        "# Visualizing change\n",
        "plt.plot(before, label=\"Before\", marker='o')\n",
        "plt.plot(after, label=\"After\", marker='x')\n",
        "plt.title(\"Before vs After - Paired T-test\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1lLwEqHZHhhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Perform a paired sample T-test using Python and visualize the comparison results@\n"
      ],
      "metadata": {
        "id": "kdmFYC6rJ1Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_1samp, norm\n",
        "\n",
        "np.random.seed(1)\n",
        "data = np.random.normal(loc=100, scale=15, size=25)\n",
        "\n",
        "# Known population std\n",
        "pop_mean = 105\n",
        "pop_std = 15\n",
        "\n",
        "# Z-test\n",
        "z = (np.mean(data) - pop_mean) / (pop_std / np.sqrt(len(data)))\n",
        "z_p = 2 * (1 - norm.cdf(abs(z)))\n",
        "\n",
        "# T-test\n",
        "t_stat, t_p = ttest_1samp(data, pop_mean)\n",
        "\n",
        "print(\"Z-test -> Z:\", z, \"P-value:\", z_p)\n",
        "print(\"T-test -> T:\", t_stat, \"P-value:\", t_p)\n"
      ],
      "metadata": {
        "id": "evPJdYnyHha9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n"
      ],
      "metadata": {
        "id": "Phh9Wz_iJ7dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    mean = np.mean(data)\n",
        "    n = len(data)\n",
        "    se = np.std(data, ddof=1) / np.sqrt(n)\n",
        "    t_crit = t.ppf((1 + confidence) / 2, df=n-1)\n",
        "    margin = t_crit * se\n",
        "    return mean - margin, mean + margin\n",
        "\n",
        "# Example\n",
        "data = [45, 50, 47, 49, 48, 46]\n",
        "ci = confidence_interval(data)\n",
        "print(\"Confidence Interval:\", ci)\n"
      ],
      "metadata": {
        "id": "qjaGP0M-HhWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to calculate the margin of error for a given confidence level using sample dataD\n"
      ],
      "metadata": {
        "id": "t3hp-bQxJ_nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "\n",
        "def margin_of_error(data, confidence=0.95):\n",
        "    n = len(data)\n",
        "    se = np.std(data, ddof=1) / np.sqrt(n)\n",
        "    t_val = t.ppf((1 + confidence) / 2, n - 1)\n",
        "    return t_val * se\n",
        "\n",
        "# Sample data\n",
        "sample = [200, 210, 205, 215, 220]\n",
        "moe = margin_of_error(sample)\n",
        "print(\"Margin of Error:\", moe)\n"
      ],
      "metadata": {
        "id": "6Sed4a84HhQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Implement a Bayesian inference method using Bayes' Theorem in Python and explain the processD\n"
      ],
      "metadata": {
        "id": "YUStfADCKDhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bayes_theorem(prior_A, prob_B_given_A, prob_B):\n",
        "    return (prob_B_given_A * prior_A) / prob_B\n",
        "\n",
        "# Example:\n",
        "# P(Disease) = 0.01\n",
        "# P(Positive | Disease) = 0.99\n",
        "# P(Positive) = 0.05\n",
        "\n",
        "posterior = bayes_theorem(0.01, 0.99, 0.05)\n",
        "print(\"Posterior Probability (Disease | Positive Test):\", posterior)\n"
      ],
      "metadata": {
        "id": "5-eYjqlzHhKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Perform a Chi-square test for independence between two categorical variables in PythonD\n"
      ],
      "metadata": {
        "id": "8M9M6s4NKJUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Example: Gender vs Preference\n",
        "data = pd.DataFrame({\n",
        "    'Likes': [30, 20],\n",
        "    'Dislikes': [10, 40]\n",
        "}, index=['Male', 'Female'])\n",
        "\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "\n",
        "print(\"Chi-square Statistic:\", chi2)\n",
        "print(\"P-value:\", p)\n",
        "print(\"Expected Frequencies:\\n\", expected)\n"
      ],
      "metadata": {
        "id": "ZuplBMHRHhEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Write a Python program to calculate the expected frequencies for a Chi-square test based on observed\n",
        "dataD"
      ],
      "metadata": {
        "id": "aUNyyFusKMQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Observed data\n",
        "data = pd.DataFrame({\n",
        "    'Yes': [25, 30],\n",
        "    'No': [15, 20]\n",
        "}, index=['Group A', 'Group B'])\n",
        "\n",
        "# Calculate expected freq\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "\n",
        "print(\"Expected Frequencies:\\n\", expected)\n"
      ],
      "metadata": {
        "id": "sZxVz_ODHg93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution\n"
      ],
      "metadata": {
        "id": "Ol1tPKn6KUKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chisquare\n",
        "\n",
        "# observed vs expected\n",
        "observed = [18, 22, 20, 25, 15]\n",
        "expected = [20, 20, 20, 20, 20]  # uniform expected dist\n",
        "\n",
        "chi2_stat, p_val = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "print(\"Chi-square Statistic:\", chi2_stat)\n",
        "print(\"P-value:\", p_val)\n"
      ],
      "metadata": {
        "id": "2_YSyUtlHg4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics.\n"
      ],
      "metadata": {
        "id": "meKPdXG0KYud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2\n",
        "\n",
        "df = 4  # degrees of freedom\n",
        "x = np.linspace(0, 20, 500)\n",
        "y = chi2.pdf(x, df)\n",
        "\n",
        "plt.plot(x, y, label=f'df = {df}')\n",
        "plt.title(\"Chi-square Distribution\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vF40QresHgzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Implement an F-test using Python to compare the variances of two random samplesD\n"
      ],
      "metadata": {
        "id": "L4CpbbccKd1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "group1 = [21, 23, 20, 22, 24]\n",
        "group2 = [30, 35, 32, 33, 34]\n",
        "\n",
        "var1 = np.var(group1, ddof=1)\n",
        "var2 = np.var(group2, ddof=1)\n",
        "\n",
        "f_stat = var1 / var2 if var1 > var2 else var2 / var1\n",
        "d1 = len(group1) - 1\n",
        "d2 = len(group2) - 1\n",
        "\n",
        "p_val = 1 - f.cdf(f_stat, d1, d2)\n",
        "\n",
        "print(\"F-statistic:\", f_stat)\n",
        "print(\"P-value:\", p_val)\n"
      ],
      "metadata": {
        "id": "toWbctrWHgtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to perform an ANOVA test to compare means between multiple groups and interpret the resultsD."
      ],
      "metadata": {
        "id": "pRy0rK48Kh9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "group1 = [88, 90, 85, 87]\n",
        "group2 = [78, 76, 75, 79]\n",
        "group3 = [92, 94, 91, 93]\n",
        "\n",
        "f_stat, p_val = f_oneway(group1, group2, group3)\n",
        "\n",
        "print(\"F-statistic:\", f_stat)\n",
        "print(\"P-value:\", p_val)\n"
      ],
      "metadata": {
        "id": "bVsQnBpKHgnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.  Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results.\n"
      ],
      "metadata": {
        "id": "5GMymiw7KoZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# reuse groups from last example\n",
        "groups = [group1, group2, group3]\n",
        "\n",
        "# boxplot\n",
        "plt.boxplot(groups, labels=[\"Group 1\", \"Group 2\", \"Group 3\"])\n",
        "plt.title(\"Group Comparison using One-way ANOVA\")\n",
        "plt.ylabel(\"Scores\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qQxCuqFIHge1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA.\n"
      ],
      "metadata": {
        "id": "Thn4LDe5Kv0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "def check_anova_assumptions(*groups):\n",
        "    # Normality test\n",
        "    for i, g in enumerate(groups):\n",
        "        stat, p = stats.shapiro(g)\n",
        "        print(f\"Group {i+1} normality p-value:\", p)\n",
        "\n",
        "    # Equal variance test\n",
        "    stat, p = stats.levene(*groups)\n",
        "    print(\"Levene’s test for equal variances p-value:\", p)\n",
        "\n",
        "# Example groups\n",
        "g1 = [14, 15, 16, 13, 17]\n",
        "g2 = [22, 20, 21, 23, 19]\n",
        "g3 = [30, 29, 28, 31, 27]\n",
        "\n",
        "check_anova_assumptions(g1, g2, g3)\n"
      ],
      "metadata": {
        "id": "lEeTz94HHgU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the results."
      ],
      "metadata": {
        "id": "0PRlCB8MK2gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import pandas as pd\n",
        "\n",
        "# sample data\n",
        "data = pd.DataFrame({\n",
        "    'Score': [80, 85, 78, 90, 88, 75, 70, 72, 68, 71, 60, 63],\n",
        "    'Method': ['A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B'],\n",
        "    'Gender': ['M', 'M', 'F', 'F', 'M', 'F', 'M', 'M', 'F', 'F', 'M', 'F']\n",
        "})\n",
        "\n",
        "model = ols('Score ~ C(Method) + C(Gender) + C(Method):C(Gender)', data=data).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_table)\n"
      ],
      "metadata": {
        "id": "onOuA7MJHgEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing"
      ],
      "metadata": {
        "id": "sjbDJRVGK8yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "x = np.linspace(0, 5, 500)\n",
        "df1, df2 = 5, 10\n",
        "y = f.pdf(x, df1, df2)\n",
        "\n",
        "plt.plot(x, y, label=f\"df1={df1}, df2={df2}\")\n",
        "plt.title(\"F-distribution\")\n",
        "plt.xlabel(\"F value\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EAcN8Tm_Iz8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 22. Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means"
      ],
      "metadata": {
        "id": "MErO2dDoL16y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "group1 = [10, 12, 13, 11]\n",
        "group2 = [14, 15, 13, 16]\n",
        "group3 = [18, 17, 19, 20]\n",
        "\n",
        "f_stat, p_val = f_oneway(group1, group2, group3)\n",
        "print(\"F-statistic:\", f_stat)\n",
        "print(\"P-value:\", p_val)\n",
        "\n",
        "plt.boxplot([group1, group2, group3], labels=[\"G1\", \"G2\", \"G3\"])\n",
        "plt.title(\"One-way ANOVA - Boxplot\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Kp0y8fbYIzxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means"
      ],
      "metadata": {
        "id": "-g0E1wJcL7Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "np.random.seed(5)\n",
        "data = np.random.normal(loc=100, scale=10, size=30)\n",
        "\n",
        "# Test if mean = 102\n",
        "t_stat, p_val = ttest_1samp(data, 102)\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_val)\n"
      ],
      "metadata": {
        "id": "HzY56FYFI_hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results"
      ],
      "metadata": {
        "id": "k0YM1IfcMAqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2\n",
        "\n",
        "data = [20, 22, 21, 19, 23, 20, 22]\n",
        "sample_var = np.var(data, ddof=1)\n",
        "n = len(data)\n",
        "pop_var = 4\n",
        "\n",
        "chi_sq = (n - 1) * sample_var / pop_var\n",
        "p_val = 2 * min(chi2.cdf(chi_sq, df=n-1), 1 - chi2.cdf(chi_sq, df=n-1))\n",
        "\n",
        "print(\"Chi-square stat:\", chi_sq)\n",
        "print(\"P-value:\", p_val)\n"
      ],
      "metadata": {
        "id": "6eY14c3NJAzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python script to perform a Z-test for comparing proportions between two datasets or groups"
      ],
      "metadata": {
        "id": "j-ZcjI3VMQwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "success = [45, 30]\n",
        "nobs = [100, 100]\n",
        "\n",
        "z_stat, p_val = proportions_ztest(success, nobs)\n",
        "\n",
        "print(\"Z-statistic:\", z_stat)\n",
        "print(\"P-value:\", p_val)\n"
      ],
      "metadata": {
        "id": "4mbA1X6hJApO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 26. mplement an F-test for comparing the variances of two datasets, then interpret and visualize the results"
      ],
      "metadata": {
        "id": "FF0euwPeMV-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "group1 = [24, 25, 22, 23, 24]\n",
        "group2 = [30, 35, 28, 32, 31]\n",
        "\n",
        "var1 = np.var(group1, ddof=1)\n",
        "var2 = np.var(group2, ddof=1)\n",
        "\n",
        "f_stat = max(var1, var2) / min(var1, var2)\n",
        "print(\"F-statistic:\", f_stat)\n",
        "\n",
        "plt.hist(group1, alpha=0.5, label='Group 1')\n",
        "plt.hist(group2, alpha=0.5, label='Group 2')\n",
        "plt.title(\"Variance Comparison - Histogram\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l6Y9tHbjJAg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Perform a Chi-square test for goodness of fit with simulated data and analyze the results"
      ],
      "metadata": {
        "id": "p3SScbz7MeNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chisquare\n",
        "\n",
        "# simulate observed data\n",
        "observed = [18, 22, 20, 25, 15]\n",
        "expected = [20, 20, 20, 20, 20]  # expected uniform distribution\n",
        "\n",
        "chi2_stat, p_val = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "print(\"Chi-square statistic:\", chi2_stat)\n",
        "print(\"P-value:\", p_val)\n"
      ],
      "metadata": {
        "id": "BmBEJMYSJAYc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}